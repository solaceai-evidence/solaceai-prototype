# API key for Semantic Scholar - used to retrieve paper passages, search results, and metadata
S2_API_KEY=

# API key for Anthropic Claude models - primary LLM for content generation and analysis
ANTHROPIC_API_KEY=

# API key for OpenAI models - used as fallback LLM and for content moderation/validation
OPENAI_API_KEY=

# Modal cloud platform credentials - required when using Modal for remote model deployment
MODAL_TOKEN=
MODAL_TOKEN_SECRET=

# Remote reranker service configuration
# Configure these when using a standalone reranker service (not Modal or Docker)
# Host address for the remote reranker service
RERANKER_HOST=
# Port number for the remote reranker service
RERANKER_PORT=

# LLM concurrency and rate limiting configuration
# Maximum number of concurrent LLM workers for parallel processing
MAX_LLM_WORKERS=3

# Maximum API requests per minute - set according to your LLM provider quota
RATE_LIMIT_RPM=

# Maximum input tokens per minute across all LLM requests - prevents quota overrun
RATE_LIMIT_ITPM=

# Maximum output tokens per minute across all LLM requests - controls generation limits
RATE_LIMIT_OTPM=

# Reranker service timeout and concurrency settings
# Client timeout in seconds when communicating with remote reranker
RERANKER_CLIENT_TIMEOUT=

# Maximum concurrent reranker requests - controls resource usage
MAX_CONCURRENCY=

# Request processing timeout in milliseconds for reranker operations
RERANKER_TIMEOUT_MS=

# Queue wait timeout in milliseconds before rejecting reranker requests
RERANKER_QUEUE_TIMEOUT_MS=
